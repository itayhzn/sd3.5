{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6f428f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2f7e043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensors_aux(dir, pt_name_predicate=None):\n",
    "    \"\"\" recursively read tensors from a directory \"\"\"\n",
    "    if pt_name_predicate is None:\n",
    "        pt_name_predicate = lambda x, y: True\n",
    "    tensors = {}\n",
    "    for path in os.listdir(dir):\n",
    "        if path.endswith('.pt'):\n",
    "            key = path[:-3]\n",
    "            if pt_name_predicate is None or pt_name_predicate(key, dir):\n",
    "                try:\n",
    "                    tensors[key] = torch.load(os.path.join(dir, path))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {path}: {e}\")\n",
    "        elif os.path.isdir(os.path.join(dir, path)):\n",
    "            key = path.split('_')[1] if path.startswith('timestep_') else path \n",
    "            tensors[key] = read_tensors_aux(os.path.join(dir, path), pt_name_predicate)\n",
    "        else:\n",
    "            print(f\"Skipping {path}, not a tensor or directory\")\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8489d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'tensors/outputs/sd3.5_medium/dift'\n",
    "gen_experiments = os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f337e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 20251019_051518_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_15, Seed: 15\n",
      "Experiment: 20251019_050908_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_11, Seed: 11\n",
      "Experiment: 20251019_051205_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_13, Seed: 13\n",
      "Experiment: 20251019_051640_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_16, Seed: 16\n",
      "Experiment: 20251019_051138_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_12, Seed: 12\n",
      "Experiment: 20251019_051339_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_14, Seed: 14\n",
      "Experiment: 20251019_051628_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_15, Seed: 15\n",
      "Experiment: 20251019_051034_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_12, Seed: 12\n",
      "Experiment: 20251019_051008_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_11, Seed: 11\n",
      "Experiment: 20251019_051815_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_17, Seed: 17\n",
      "Experiment: 20251019_051800_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_16, Seed: 16\n",
      "Experiment: 20251019_050839_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_23, Seed: 23\n",
      "Experiment: 20251019_051946_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_17, Seed: 17\n",
      "Experiment: 20251019_050746_dift-01_-.h*.Lskip-.Lresgate*.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_23, Seed: 23\n",
      "Experiment: 20251019_051450_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_14, Seed: 14\n",
      "Experiment: 20251019_051315_dift-02_-.h*.Lskip-.Lresgate*.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_13, Seed: 13\n"
     ]
    }
   ],
   "source": [
    "for exp in gen_experiments:\n",
    "    exp_dir = os.path.join(dir, exp, '000000')\n",
    "    seed = int(exp.split('_')[-1])\n",
    "    print(f\"Experiment: {exp}, Seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_full_name = [e for e in gen_experiments if exp_short_name in e][0]\n",
    "exp_dir = os.path.join(dir, exp_full_name, '000000')\n",
    "tensors = read_tensors_aux(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b19636",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors['x_t=1000'].shape, tensors['pos_out_t=1000'].shape, tensors['neg_out_t=1000'].shape, tensors['x_grad_t=1000'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d078c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_t = [tensors[f'x_grad_t={t:04d}'] for t in range(1000, -1, -1) if f'x_grad_t={t:04d}' in tensors]\n",
    "x_t = [tensors[f'x_t={t:04d}'] for t in range(1000, -1, -1) if f'x_t={t:04d}' in tensors]\n",
    "pos_out_t = [tensors[f'pos_out_t={t:04d}'] for t in range(1000, -1, -1) if f'pos_out_t={t:04d}' in tensors]\n",
    "neg_out_t = [tensors[f'neg_out_t={t:04d}'] for t in range(1000, -1, -1) if f'neg_out_t={t:04d}' in tensors]\n",
    "\n",
    "grad_t = torch.stack(grad_t).permute(0, 2, 3, 1).cpu().numpy()\n",
    "x_t = torch.stack(x_t).permute(0, 2, 3, 1).cpu().numpy()\n",
    "pos_out_t = torch.stack(pos_out_t).permute(0, 2, 3, 1).cpu().numpy()\n",
    "neg_out_t = torch.stack(neg_out_t).permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "# max pool over channels\n",
    "grad_t_max = np.max(np.abs(grad_t), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad115214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_t_max.shape is (T=50, W=128, H=128)\n",
    "# plot a grid of images of grad_t_max\n",
    "def plot_grid(tensors, suptitle, title_fn=lambda x: f't={x}', nrows=5, ncols=10, figsize=(20, 10), cmap='viridis', normalize=False, save_path=None):\n",
    "    if normalize and tensors.max() > tensors.min():\n",
    "        tensors = (tensors - tensors.min()) / (tensors.max() - tensors.min())\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            t = i * ncols + j\n",
    "            if t < tensors.shape[0]:\n",
    "                ax[i, j].imshow(tensors[t], cmap=cmap)\n",
    "                ax[i, j].set_title(title_fn(t))\n",
    "                ax[i, j].axis('off')\n",
    "            else:\n",
    "                ax[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(suptitle, fontsize=40, y=1.05)\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(f'visualizations/{save_path}'), exist_ok=True)\n",
    "        plt.savefig(f'visualizations/{save_path}', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(grad_t_max, f'Conditioning Saliency Maps (experiment: {exp_short_name})', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(x_t[:,:,:,7], 'x_t (channel 7)', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(x_t[49,:,:,:].transpose(2,0,1), 'x_t at t=49 (all channels)', title_prefix='c=', nrows=2, ncols=8, figsize=(20,10), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(pos_out_t[:,:,:,7], 'Conditioned Model Output (channel 7)', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(neg_out_t[:,:,:,7], 'Unconditioned Model Output (channel 7)', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8bc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484a457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('outputs/sd3.5_medium')\n",
    "files = [f for f in files if 'dataset-01' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    os.system(f'cp outputs/sd3.5_medium/{f}/000000.png dataset_images/{f[:16]}{f[27:-3]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0][:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_mass(grads):\n",
    "    \"\"\"\n",
    "        grads: tensor of shape (T, W, H) or list of tensors of shape (W, H)\n",
    "        Returns: tensor of shape (T,) with the saliency mass for each timestep\n",
    "    \"\"\"\n",
    "    if isinstance(grads, list):\n",
    "        grads = torch.tensor(grads)\n",
    "    # grads = torch.max(grads, axis=1)  # max pooling over channels\n",
    "    # W,H = grads.shape[1], grads.shape[2]\n",
    "    return torch.sum(torch.abs(grads), axis=(1, 2)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_in_stream(base_dir='tensors/outputs/sd3.5_medium', dir_perdicate=lambda x: True, tensor_predicate=lambda x, d: x.startswith('x_grad_t='), metric_fn=lambda x: np.mean(np.array(x))):\n",
    "    metrics = []\n",
    "    for path in os.listdir(dir):\n",
    "        if not dir_perdicate(path):\n",
    "            continue\n",
    "        tensors = read_tensors_aux(os.path.join(base_dir, path, '000000'), tensor_predicate)\n",
    "        ks = sorted(list(tensors.keys()))[::-1]\n",
    "        grad = np.array([tensors[k] for k in ks])\n",
    "        for k, v in tensors.items():\n",
    "            d = { 'path': path}\n",
    "            d['tensor_name'] = ''.join(k.split('=')[:-1])\n",
    "            d['timestep'] =int(k.split('=')[-1])\n",
    "            d['value'] = metric_fn(v[np.newaxis, ...])[0]\n",
    "            metrics.append(d)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metric_in_stream(metric_fn=compute_saliency_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(compute_metric_in_stream(metric_fn=compute_saliency_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tensor_metrics_df.csv')\n",
    "df['escaped_prompt'] = df['path'].apply(lambda x: x[31:x.rfind('_')])\n",
    "df['seed'] = df['path'].apply(lambda x: int(x[x.rfind('_')+1:]))\n",
    "df = df.sort_values(by='path')\n",
    "\n",
    "labels_df = pd.read_excel('hallucinations_dataset.xlsx')\n",
    "labels_df['escaped_prompt'] = labels_df['prompt'].apply(lambda x: re.sub(r\"[^\\w\\-\\.]\", \"_\", x)[:50])\n",
    "\n",
    "# inner join to add labels to df\n",
    "df = df.merge(labels_df, on='escaped_prompt', how='inner')\n",
    "\n",
    "# # df has four columns: path, tensor_name, timestep, saliency_mass\n",
    "# # Create a column 'normalized_value' which is the value divided by the value at timestep 1000 for that path and tensor_name\n",
    "values_at_1000 = df[df['timestep'] == 1000][['path', 'tensor_name', 'value', 'metric_name']]\n",
    "df = df.merge(values_at_1000, on=['path', 'tensor_name', 'metric_name'], suffixes=('', '_at_1000'))\n",
    "df['normalized_value'] = df['value'] / df['value_at_1000']\n",
    "# for metric_name in ['saliency_mass', 'l2', 'l1', 'max', 'mean', 'var', 'var_on_diff', 'var_on_abs_diff']:\n",
    "#    df[f'normalized_value'] = df.apply(lambda row: row['value'] / df[(df['path'] == row['path']) & (df['tensor_name'] == row['tensor_name']) & (df['timestep'] == 1000) & (df['metric_name'] == row['metric_name'])]['value'].values[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['timestep'] == 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'hallucinations'  # or 'coherence'\n",
    "for metric in ['var_on_diff', 'var_on_abs_diff', 'saliency_mass', 'l2', 'l1', 'max', 'mean', 'var']:\n",
    "    # plot normalized_saliency_mass over timestep for each value of hallucination\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df[(df['metric_name'] == metric) & (df[label_name].isin([0,2]))], x='timestep', y='normalized_value', hue=label_name, markers=True, dashes=False, palette='tab10')\n",
    "    plt.yscale('log')\n",
    "    plt.title(f'{metric.capitalize()} over Timesteps')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.xlim(1000, 800)\n",
    "    plt.ylabel(f'{metric.capitalize()}') \n",
    "    plt.legend(title=f'{label_name.capitalize()} level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60260bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee126c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = {\n",
    "    'Hallucination (gymnastics)': '20251002_022502_dataset-03_-.*_A_trapeze_duo_swapping_bars_mid-air_while_twisting_23',\n",
    "    'Hallucination (fidget spinner)': '20251001_180741_dataset-03_-.*_A_hand_holding_a_yellow_fidget_spinner._The_hand_i_23',\n",
    "    'Normal (dog with ball)': '20251001_170130_dataset-03_-.*_A_dog_playing_with_an_orange_ball_with_blue_stripe_23',\n",
    "    'Normal (walking in field)': '20251001_175612_dataset-03_-.*_A_cinematic_shot_of_a_person_walking_along_a_quiet_23'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['path'].isin(examples.values())]['prompt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_concat(dir, tensor_predicate=None):\n",
    "    tensors = read_tensors_aux(dir, tensor_predicate)\n",
    "    ks = sorted(list(tensors.keys()))[::-1]\n",
    "    t = np.array([tensors[k] for k in ks])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc78212",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_tensors = {name: read_concat(os.path.join(dir, path, '000000'), lambda x, d: x.startswith('x_grad_t=')) for name, path in examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_tensors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d64651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, t in examples_tensors.items():\n",
    "    plot_grid(t, f\"{name}\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_var = {name: torch.var(torch.tensor(t), dim=1).cpu().numpy() for name, t in examples_tensors.items()}\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Variance over Columns of Saliency Maps', fontsize=25)\n",
    "\n",
    "for i, (name, var) in enumerate(col_var.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(var, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Variance')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Width (W)')\n",
    "    plt.ylabel('Timestep')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_var = {name: torch.var(torch.abs(torch.tensor(t)), dim=2).cpu().numpy() for name, t in examples_tensors.items()}\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Variance per Row of Saliency Maps', fontsize=25)\n",
    "\n",
    "for i, (name, var) in enumerate(row_var.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(var, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Variance')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Width (W)')\n",
    "    plt.ylabel('Timestep')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ca7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_var = {name: torch.var(torch.abs(torch.tensor(t)), dim=1).cpu().numpy() for name, t in examples_tensors.items()}\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Variance over Columns of Saliency Maps', fontsize=25)\n",
    "\n",
    "for i, (name, var) in enumerate(col_var.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(var, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Variance')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Width (W)')\n",
    "    plt.ylabel('Timestep')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_var = {name: torch.var(torch.abs(torch.tensor(t)), dim=2).cpu().numpy() for name, t in examples_tensors.items()}\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Variance per Row of Saliency Maps', fontsize=25)\n",
    "\n",
    "for i, (name, var) in enumerate(row_var.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(var, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Variance')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Width (W)')\n",
    "    plt.ylabel('Timestep')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = {name: torch.var(torch.abs(torch.diff(torch.tensor(t), dim=0)[:20,:,:]), dim=0).cpu().numpy() for name, t in examples_tensors.items()}\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Variance per Column of Saliency Maps', fontsize=25)\n",
    "\n",
    "for i, (name, var) in enumerate(time_var.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(var, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Variance')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Width (W)')\n",
    "    plt.ylabel('Timestep')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcbc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_short_name(df, examples):\n",
    "    short_names = {v: k for k, v in examples.items()}\n",
    "    df['short_name'] = df['path'].apply(lambda x: short_names.get(x, 'Unknown'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'hallucinations'  # or 'coherence'\n",
    "filenames = examples.values()\n",
    "for metric in ['var_on_diff', 'var_on_abs_diff', 'saliency_mass', 'l2', 'l1', 'max', 'mean', 'var']:\n",
    "    # plot normalized_saliency_mass over timestep for each value of hallucination\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df[(df['metric_name'] == metric) & (df[label_name].isin([0,2])) & (df['path'].isin(filenames))], x='timestep', y='normalized_value', hue='short_name', markers=True, dashes=False, palette='tab10')\n",
    "    plt.yscale('log')\n",
    "    plt.title(f'{metric.capitalize()} over Timesteps')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.xlim(1000, 800)\n",
    "    plt.ylabel(f'{metric.capitalize()}') \n",
    "    plt.legend(title=f'{label_name.capitalize()} level', loc='lower center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_short_name(df, examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['metric_name'] == metric) & (df[label_name].isin([0,2])) & (df['path'].isin(filenames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39781e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f31cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_dir = 'tensors/outputs/sd3.5_medium/dog/'\n",
    "dog_files = { f[f.index('.')+2:f.index('.')+2+f[f.index('.')+2:].index('.')]: f for f in os.listdir(dog_dir) }\n",
    "dog_files = { int(k if k != '*' else -1) : v for k, v in dog_files.items() }\n",
    "dog_tensors = { h: read_tensors_aux(dog_dir + exp_dir)['000000'] for h, exp_dir in dog_files.items() }\n",
    "dog_tensors = { h: torch.stack([tlist[k] for k in sorted(list(tlist.keys()))[::-1] ]) for h, tlist in dog_tensors.items() }\n",
    "dog_tensors = torch.stack([dog_tensors[h] for h in sorted(dog_tensors.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(dog_tensors.shape[0]):\n",
    "    plot_grid(dog_tensors[h].cpu().numpy(), f\"Dog experiment, head={h if h >= 0 else '*'}\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a34d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(50):\n",
    "    plot_grid(dog_tensors[:,t,:,:].cpu().numpy(), f\"Dog experiment, timestep={t}\", title_fn=lambda x: f'head={x-1}' if x > 0 else 'all heads', nrows=5, ncols=5, figsize=(20, 15), normalize=False, save_path=f'attn_heads/dog_not_normalized/timestep_{t:02d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9462a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_from_dir(dir, save_dir=None, fps=5):\n",
    "    images = []\n",
    "    for file in sorted(os.listdir(dir)):\n",
    "        if file.endswith('.png'):\n",
    "            img = plt.imread(os.path.join(dir, file))\n",
    "            images.append(img)\n",
    "    fig = plt.figure()\n",
    "    plt.axis('off')\n",
    "    ims = [[plt.imshow(img, animated=True)] for img in images]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000/fps, blit=True, repeat_delay=1000)\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    if save_dir is None:\n",
    "        save_dir = dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    ani.save(os.path.join(save_dir, 'animation.mp4'), writer='ffmpeg', fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c20017",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video_from_dir('visualizations/attn_heads/dog_normalized', fps=5)\n",
    "save_video_from_dir('visualizations/attn_heads/dog_not_normalized', fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5dd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
